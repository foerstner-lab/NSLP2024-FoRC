{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# FoRC Task 1, Subtask A:\n",
    "- feature-based approach\n",
    "- no enrichments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUaaIOegOtMz"
   },
   "outputs": [],
   "source": [
    "# uncomment following lines for installation\n",
    "# !pip install datasets\n",
    "# !pip install accelerate -U\n",
    "# !pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCnVzRxXOclk"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    BertConfig,\n",
    "    get_scheduler,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCULWreTOutv"
   },
   "outputs": [],
   "source": [
    "# device agnostic code\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Cuda-Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82o0zVkrdgGP"
   },
   "source": [
    "# 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yptk-imJuHi"
   },
   "source": [
    "## 1.1 Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXymAeKJoqd8"
   },
   "outputs": [],
   "source": [
    "hf_models = [\"bert-base-uncased\", \"allenai/scibert_scivocab_uncased\", \"malteos/scincl\", \"allenai/specter2_base\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DOZz44vfjWeq"
   },
   "outputs": [],
   "source": [
    "hf_model = hf_models[3]\n",
    "hf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GaPWikZHR7es"
   },
   "outputs": [],
   "source": [
    "def load_dataset(f: Path, features: dict):\n",
    "    data = pd.read_csv(f)\n",
    "    x = data[features]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhZa3WUXKJea"
   },
   "outputs": [],
   "source": [
    "# path to datasets\n",
    "path_data = Path(\"../datasets\")\n",
    "\n",
    "# Load cleaned/preprocessed datasets, not enriched\n",
    "f_train = path_data / \"train_cleaned.csv\"\n",
    "f_val = path_data / \"val_cleaned.csv\"\n",
    "\n",
    "# define data mapping\n",
    "features = [\"abstract\", \"title\", \"label\"]\n",
    "\n",
    "df_train = load_dataset(f_train, features)\n",
    "df_val = load_dataset(f_val, features)\n",
    "\n",
    "print(f\"Train has {len(df_train)} samples\")\n",
    "print(f\"Validation has {len(df_val)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhmsv5JpKKow"
   },
   "source": [
    "## 1.2 Clean and prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzMhgEilKLEw"
   },
   "outputs": [],
   "source": [
    "def count_nan(df):\n",
    "    df_nan = df[df.isna().any(axis=1)]\n",
    "    return len(df_nan)\n",
    "\n",
    "\n",
    "print(f\"Before cleaning:\")\n",
    "print(f\"train-samples with NaN:{count_nan(df_train)}\")\n",
    "print(f\"val-samples with NaN:{count_nan(df_val)}\")\n",
    "\n",
    "# remove nan values (inplace) with emptry string (we only have string values here)\n",
    "df_train.fillna(\"\", inplace=True)\n",
    "df_val.fillna(\"\", inplace=True)\n",
    "\n",
    "print(f\"\\nAfter cleaning:\")\n",
    "print(f\"train-samples with NaN:{count_nan(df_train)}\")\n",
    "print(f\"val-samples with NaN:{count_nan(df_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqjF7RFB9PhI"
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JS12uQP96bAr"
   },
   "outputs": [],
   "source": [
    "# encode labels to numbers\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train[\"label\"])\n",
    "df_train[\"labels\"] = le.transform(df_train[\"label\"])\n",
    "df_val[\"labels\"] = le.transform(df_val[\"label\"])\n",
    "df_train[\"labels\"][:5], df_val[\"labels\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m5yrdtQnKQTI"
   },
   "outputs": [],
   "source": [
    "# create tokenizer (pretrained for scientific papers)\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlGA6uWp6a3P"
   },
   "outputs": [],
   "source": [
    "# Show label and label id\n",
    "df_train[[\"label\", \"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVDm7HdFk2Av"
   },
   "outputs": [],
   "source": [
    "df_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Rdlc3lmMFec"
   },
   "outputs": [],
   "source": [
    "# Concatenate title and abstract as text input for BERT\n",
    "df_train[\"text\"] = df_train[\"title\"] + tokenizer.sep_token + df_train[\"abstract\"]\n",
    "\n",
    "df_val[\"text\"] = df_val[\"title\"] + tokenizer.sep_token + df_val[\"abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qz3NcsQqMUJr"
   },
   "outputs": [],
   "source": [
    "# Remove irrelevant columns (only labels and text needed)\n",
    "df_train = df_train[[\"labels\", \"text\"]]\n",
    "df_val = df_val[[\"labels\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCL62dF66agF"
   },
   "outputs": [],
   "source": [
    "# Create Dataset (train)\n",
    "ds_train = Dataset(pa.Table.from_pandas(df_train))\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDxSlFKo5UEx"
   },
   "outputs": [],
   "source": [
    "# Create Dataset (validation)\n",
    "ds_val = Dataset(pa.Table.from_pandas(df_val))\n",
    "ds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKj8y4NicTar"
   },
   "outputs": [],
   "source": [
    "# Create DatasetDict\n",
    "dd = DatasetDict({\"train\": ds_train, \"validation\": ds_val})\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dv3rv_lFQR8R"
   },
   "outputs": [],
   "source": [
    "# tokenize function\n",
    "def tokenize_function(row):\n",
    "    return tokenizer(row[\"text\"], padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6PQ8tAFQSP7"
   },
   "outputs": [],
   "source": [
    "# apply tokenization in dataset\n",
    "dd_tokenized = dd.map(tokenize_function, batched=True, batch_size=42000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xerq2PBCfZNP"
   },
   "outputs": [],
   "source": [
    "# set format to torch\n",
    "dd_tokenized.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMfWZUb570wC"
   },
   "outputs": [],
   "source": [
    "ds_train = dd_tokenized[\"train\"]\n",
    "ds_val = dd_tokenized[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8bZ3XPh11Ue"
   },
   "outputs": [],
   "source": [
    "dd_tokenized[\"train\"] = dd_tokenized[\"train\"].remove_columns([\"text\"])\n",
    "dd_tokenized[\"validation\"] = dd_tokenized[\"validation\"].remove_columns([\"text\"])\n",
    "dd_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xupPOmi2dq9K"
   },
   "source": [
    "# 2. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUdmI7uGKLcV"
   },
   "source": [
    "## 2.1 Build Model and prepare Dataset for iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPkkEWb3K_qc"
   },
   "outputs": [],
   "source": [
    "# create the model (here a Bert with DenseLayer on top)\n",
    "# Note: For more than 2 Labels the standard loss_fn is CrossEntropyLoss()\n",
    "model = AutoModelForSequenceClassification.from_pretrained(hf_model, num_labels=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jvwoa2Dqrjmt"
   },
   "outputs": [],
   "source": [
    "# freeze BERT (but not dense-layer)\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJcDplPrK_9f"
   },
   "source": [
    "## 2.2 Setup loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xH7fkr75sgb2"
   },
   "outputs": [],
   "source": [
    "# send model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUUSg60RLAE-"
   },
   "source": [
    "## 2.3 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkuI_H45sU39"
   },
   "outputs": [],
   "source": [
    "# Metrics for evaluation\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average=\"weighted\")\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average=\"weighted\")\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBJOgjMeza_W"
   },
   "outputs": [],
   "source": [
    "# Train with trainer\n",
    "\n",
    "# Define Trainer\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"\",  # add output directore\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.001,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_val,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r026xS2zIIll"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSxMFrRzsf1O"
   },
   "source": [
    "## 2.4 Write Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJkWno4Dsbv-"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"\")  # add save path for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxAOnJcLeDAV"
   },
   "source": [
    "# 3. Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfN2uvyWN9H2"
   },
   "source": [
    "## 3.1 Load Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2ynj0b_N9DV"
   },
   "outputs": [],
   "source": [
    "# create validation dataloader\n",
    "f_val = path_data / \"test_cleaned.csv\"\n",
    "features = [\"data_index\", \"title\", \"abstract\"]\n",
    "df_test = pd.read_csv(f_val)\n",
    "df_test = df_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwF4SarmcdoR"
   },
   "outputs": [],
   "source": [
    "df_test.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9JE0RsEvJhL"
   },
   "source": [
    "## 3.2 Create predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIGYqWyavPFa"
   },
   "outputs": [],
   "source": [
    "# remove nan from abstracts\n",
    "df_test.fillna(\"\", inplace=True)\n",
    "# Get text\n",
    "df_test[\"text\"] = df_test[\"title\"] + tokenizer.sep_token + df_test[\"abstract\"]\n",
    "test_data = df_test[[\"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EsTg6t7yaW2"
   },
   "source": [
    "## 3.3 Convert to HF dataset and make DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtrSWvdDyfH9"
   },
   "outputs": [],
   "source": [
    "# Create DatasetDict from test dataset\n",
    "test_dataset = Dataset(pa.Table.from_pandas(test_data))\n",
    "dd_test = DatasetDict({\"test\": test_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYhtCklb01oN"
   },
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "test_tokenized = dd_test.map(tokenize_function, batched=True)\n",
    "test_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THNdtL041QYO"
   },
   "outputs": [],
   "source": [
    "# remove unnecessary columns from dataset\n",
    "test_tokenized = test_tokenized.remove_columns([\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNwXTNDj1aEV"
   },
   "outputs": [],
   "source": [
    "test_tokenized.set_format(\"torch\")\n",
    "test_dataloader = DataLoader(test_tokenized[\"test\"], shuffle=False, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0djbNRMkN89M"
   },
   "source": [
    "## 3.4 Write predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBZAMNc9KLeu"
   },
   "outputs": [],
   "source": [
    "# eval loop\n",
    "test_preds = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    test_preds.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8FLBTd42IbH"
   },
   "outputs": [],
   "source": [
    "test_preds_flat = [int(item) for items in test_preds for item in items]\n",
    "test_preds_text = [le.inverse_transform([pred])[0] for pred in test_preds_flat]\n",
    "test_preds_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gic9YBjm2O2t"
   },
   "outputs": [],
   "source": [
    "f_val = \"\"  # add where to store predictions in csv-format\n",
    "df_test[\"target\"] = test_preds_text\n",
    "df_test[[\"data_index\", \"target\"]].to_csv(f_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1kPBzF6fN0G"
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19rY9fHT2KVR"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
