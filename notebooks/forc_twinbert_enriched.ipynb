{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jX2-_Z_5KVtA"
   },
   "source": [
    "# FoRC Task 1, Subtask A\n",
    "\n",
    "- finetuned approach with custom TwinBERT Model\n",
    "- with enrichments (S2AG, OpenAlex, CrossRef)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Imports and Setup"
   ],
   "metadata": {
    "id": "Y3M8uc4k_ThM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUaaIOegOtMz"
   },
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install accelerate -U\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCnVzRxXOclk"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    BertConfig,\n",
    "    get_scheduler,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zn2-W00QXbeT"
   },
   "outputs": [],
   "source": [
    "# import custom TwinBERTModel\n",
    "from twinbert import TwinBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCULWreTOutv"
   },
   "outputs": [],
   "source": [
    "# device agnostic code\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Cuda-Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data preparation"
   ],
   "metadata": {
    "id": "kGu1qsxNAIXI"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yptk-imJuHi"
   },
   "source": [
    "## 1.1 Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GaPWikZHR7es"
   },
   "outputs": [],
   "source": [
    "def load_dataset(f: Path, features: dict):\n",
    "    data = pd.read_csv(f)\n",
    "    X = data[features]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhZa3WUXKJea"
   },
   "outputs": [],
   "source": [
    "# define paths\n",
    "path_data = Path(\"../datasets\")\n",
    "\n",
    "# Load cleaned/preprocessed datasets (enriched)\n",
    "f_train = path_data / \"train_cleaned_enriched.csv\"\n",
    "f_val = path_data / \"val_cleaned_enriched.csv\"\n",
    "\n",
    "# define data mapping\n",
    "features = [\n",
    "    \"abstract\",\n",
    "    \"title\",\n",
    "    \"label\",\n",
    "    \"doi_canon\",\n",
    "    \"concepts\",\n",
    "    \"topics\",\n",
    "    \"subtopics\",\n",
    "    \"fos\",\n",
    "    \"crossref_categories\",\n",
    "    \"crossref_journal_title\",\n",
    "]\n",
    "\n",
    "df_train = load_dataset(f_train, features)\n",
    "df_val = load_dataset(f_val, features)\n",
    "\n",
    "print(f\"Train has {len(df_train)} samples\")\n",
    "print(f\"Validation has {len(df_val)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhmsv5JpKKow"
   },
   "source": [
    "## 1.2 Clean and prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzMhgEilKLEw"
   },
   "outputs": [],
   "source": [
    "def count_nan(df):\n",
    "    df_nan = df[df.isna().any(axis=1)]\n",
    "    return len(df_nan)\n",
    "\n",
    "\n",
    "print(f\"Before cleaning:\")\n",
    "print(f\"train-samples with NaN:{count_nan(df_train)}\")\n",
    "print(f\"val-samples with NaN:{count_nan(df_val)}\")\n",
    "\n",
    "# remove nan values (inplace) with emptry string (we only have string values here)\n",
    "df_train.fillna(\"\", inplace=True)\n",
    "df_val.fillna(\"\", inplace=True)\n",
    "\n",
    "print(f\"\\nAfter cleaning:\")\n",
    "print(f\"train-samples with NaN:{count_nan(df_train)}\")\n",
    "print(f\"val-samples with NaN:{count_nan(df_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqjF7RFB9PhI"
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JS12uQP96bAr"
   },
   "outputs": [],
   "source": [
    "# encode labels to numbers\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train[\"label\"])\n",
    "df_train[\"labels\"] = le.transform(df_train[\"label\"])\n",
    "df_val[\"labels\"] = le.transform(df_val[\"label\"])\n",
    "df_train[\"labels\"][:5], df_val[\"labels\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m5yrdtQnKQTI"
   },
   "outputs": [],
   "source": [
    "# create tokenizer (pretrained for scientific papers)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/specter2_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlGA6uWp6a3P"
   },
   "outputs": [],
   "source": [
    "# Show label and label id\n",
    "df_train[[\"label\", \"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVDm7HdFk2Av"
   },
   "outputs": [],
   "source": [
    "df_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4qCUhidbE8T"
   },
   "outputs": [],
   "source": [
    "df_train.keys()\n",
    "\n",
    "# Prepare BERT Model 1 input: Title+Abstract\n",
    "# Prepare BERT Model 2 input: Enrichments\n",
    "\n",
    "df_train[\"text_1\"] = df_train[\"title\"] + tokenizer.sep_token + df_train[\"abstract\"]\n",
    "df_train[\"text_2\"] = (\n",
    "    \"Fields Of Research: \"\n",
    "    + df_train[\"fos\"]\n",
    "    + tokenizer.sep_token\n",
    "    + \"Topics: \"\n",
    "    + df_train[\"topics\"]\n",
    "    + tokenizer.sep_token\n",
    "    + \"Concepts: \"\n",
    "    + df_train[\"concepts\"]\n",
    "    + tokenizer.sep_token\n",
    "    + \"Subtopics: \"\n",
    "    + df_train[\"subtopics\"]\n",
    "    + tokenizer.sep_token\n",
    "    + \"Journal Title: \"\n",
    "    + df_train[\"crossref_journal_title\"]\n",
    "    + tokenizer.sep_token\n",
    "    + \"Categories: \"\n",
    "    + df_train[\"crossref_categories\"]\n",
    "    + tokenizer.sep_token\n",
    ")\n",
    "\n",
    "df_val[\"text_1\"] = df_val[\"title\"] + tokenizer.sep_token + df_val[\"abstract\"]\n",
    "df_val[\"text_2\"] = (\n",
    "    \"Fields Of Research: \"\n",
    "    + df_val[\"fos\"]\n",
    "    + tokenizer.sep_token\n",
    "    + \"Topics: \"\n",
    "    + df_val[\"topics\"]\n",
    "    + tokenizer.sep_token\n",
    "    + \"Concepts: \"\n",
    "    + df_val[\"concepts\"]\n",
    "    + tokenizer.sep_token\n",
    "    + \"Subtopics: \"\n",
    "    + df_val[\"subtopics\"]\n",
    "    + tokenizer.sep_token\n",
    "    + \"Journal Title: \"\n",
    "    + df_val[\"crossref_journal_title\"]\n",
    "    + tokenizer.sep_token\n",
    "    + \"Categories: \"\n",
    "    + df_val[\"crossref_categories\"]\n",
    "    + tokenizer.sep_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qz3NcsQqMUJr"
   },
   "outputs": [],
   "source": [
    "# Remove other columns (not needed right now)\n",
    "df_train = df_train[[\"labels\", \"text_1\", \"text_2\"]]\n",
    "df_val = df_val[[\"labels\", \"text_1\", \"text_2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCL62dF66agF"
   },
   "outputs": [],
   "source": [
    "# Create Dataset (train)\n",
    "ds_train = Dataset(pa.Table.from_pandas(df_train))\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDxSlFKo5UEx"
   },
   "outputs": [],
   "source": [
    "# Create Dataset (validation)\n",
    "ds_val = Dataset(pa.Table.from_pandas(df_val))\n",
    "ds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKj8y4NicTar"
   },
   "outputs": [],
   "source": [
    "# Create DatasetDict\n",
    "dd = DatasetDict({\"train\": ds_train, \"validation\": ds_val})\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dv3rv_lFQR8R"
   },
   "outputs": [],
   "source": [
    "# tokenize function\n",
    "def tokenize_text_1(row):\n",
    "    tok_output_1 = tokenizer(row[\"text_1\"], padding=True, truncation=True, max_length=512)\n",
    "    tok_output_2 = tokenizer(row[\"text_2\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    # Rename keys in the tokenized_output dictionary\n",
    "    tok_output = {\n",
    "        \"input_ids_1\": tok_output_1[\"input_ids\"],\n",
    "        \"token_type_ids_1\": tok_output_1[\"token_type_ids\"],\n",
    "        \"attention_mask_1\": tok_output_1[\"attention_mask\"],\n",
    "        \"input_ids_2\": tok_output_2[\"input_ids\"],\n",
    "        \"token_type_ids_2\": tok_output_2[\"token_type_ids\"],\n",
    "        \"attention_mask_2\": tok_output_2[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "    # Return the renamed dictionary\n",
    "    return tok_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdJpND3RZ4y6"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6PQ8tAFQSP7"
   },
   "outputs": [],
   "source": [
    "# apply tokenization in dataset\n",
    "dd_tokenized = dd.map(tokenize_text_1, batched=True, batch_size=42000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xerq2PBCfZNP"
   },
   "outputs": [],
   "source": [
    "# set format to torch\n",
    "dd_tokenized.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMfWZUb570wC"
   },
   "outputs": [],
   "source": [
    "ds_train = dd_tokenized[\"train\"]\n",
    "ds_val = dd_tokenized[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8llGumMhYY1"
   },
   "outputs": [],
   "source": [
    "dd_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Training"
   ],
   "metadata": {
    "id": "H8KchATDA24a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.1 Build model and prepare dataset for iteration"
   ],
   "metadata": {
    "id": "zshGaG0FA54z"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPkkEWb3K_qc"
   },
   "outputs": [],
   "source": [
    "# Create the model (here a custom TwinBERT with DenseLayer on top)\n",
    "# Note: For more than 2 Labels the standard loss_fn is CrossEntropyLoss()\n",
    "# Adjust number of hidden layers according to your needs\n",
    "model = TwinBertForSequenceClassification.from_pretrained(\"allenai/specter2_base\", num_labels=123, num_hidden_layers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJcDplPrK_9f"
   },
   "source": [
    "## 2.2 Setup loss and optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xH7fkr75sgb2"
   },
   "outputs": [],
   "source": [
    "# Send model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUUSg60RLAE-"
   },
   "source": [
    "## 2.3 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkuI_H45sU39"
   },
   "outputs": [],
   "source": [
    "# Metrics for evaluation\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average=\"weighted\")\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average=\"weighted\")\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBJOgjMeza_W"
   },
   "outputs": [],
   "source": [
    "# Train with trainer\n",
    "\n",
    "# Define Trainer\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"\",  # add output directory\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.001,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_val,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r026xS2zIIll"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSxMFrRzsf1O"
   },
   "source": [
    "## 2.4 Write model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJkWno4Dsbv-"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"\")  # add save path for model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Predict"
   ],
   "metadata": {
    "id": "_rmx3euXBkhk"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfN2uvyWN9H2"
   },
   "source": [
    "## 3.1 Load test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2ynj0b_N9DV"
   },
   "outputs": [],
   "source": [
    "# create validation dataloader\n",
    "f_val = path_data / \"test_cleaned_enriched.csv\"\n",
    "features = cols = [\n",
    "    \"data_index\",\n",
    "    \"title\",\n",
    "    \"concepts\",\n",
    "    \"topics\",\n",
    "    \"subtopics\",\n",
    "    \"fos\",\n",
    "    \"crossref_journal_title\",\n",
    "    \"crossref_categories\",\n",
    "    \"abstract\",\n",
    "]\n",
    "df_test = pd.read_csv(f_val)\n",
    "df_test = df_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwF4SarmcdoR"
   },
   "outputs": [],
   "source": [
    "df_test.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9JE0RsEvJhL"
   },
   "source": [
    "## 3.2 Create predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIGYqWyavPFa"
   },
   "outputs": [],
   "source": [
    "# remove nan from abstracts\n",
    "df_test.fillna(\"\", inplace=True)\n",
    "# Prepare BERT text input\n",
    "\n",
    "df_test[\"text_1\"] = df_test[\"title\"] + tokenizer.sep_token + df_test[\"abstract\"]\n",
    "df_test[\"text_2\"] = (\n",
    "    \"Fields Of Research: \"\n",
    "    + df_test[\"fos\"]\n",
    "    + tokenizer.sep_token\n",
    "    + \"Topics: \"\n",
    "    + df_test[\"topics\"]\n",
    "    + tokenizer.sep_token\n",
    "    + \"Concepts: \"\n",
    "    + df_test[\"concepts\"]\n",
    "    + tokenizer.sep_token\n",
    "    + \"Subtopics: \"\n",
    "    + df_test[\"subtopics\"]\n",
    "    + tokenizer.sep_token\n",
    "    + \"Journal Title: \"\n",
    "    + df_test[\"crossref_journal_title\"]\n",
    "    + tokenizer.sep_token\n",
    "    + \"Categories: \"\n",
    "    + df_test[\"crossref_categories\"]\n",
    "    + tokenizer.sep_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5S_EttZdwwlr"
   },
   "outputs": [],
   "source": [
    "test_data = df_test[[\"text_1\", \"text_2\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EsTg6t7yaW2"
   },
   "source": [
    "## 3.3 Convert to HF dataset and make DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtrSWvdDyfH9"
   },
   "outputs": [],
   "source": [
    "test_dataset = Dataset(pa.Table.from_pandas(test_data))\n",
    "dd_test = DatasetDict({\"test\": test_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYhtCklb01oN"
   },
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "test_tokenized = dd_test.map(tokenize_text_1, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sh-fPpB_dIWM"
   },
   "outputs": [],
   "source": [
    "test_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THNdtL041QYO"
   },
   "outputs": [],
   "source": [
    "# remove unnecessary columns from dataset\n",
    "test_tokenized = test_tokenized.remove_columns([\"text_1\", \"text_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNwXTNDj1aEV"
   },
   "outputs": [],
   "source": [
    "test_tokenized.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AFXmSmTz1faU"
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_tokenized[\"test\"], shuffle=False, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0djbNRMkN89M"
   },
   "source": [
    "## 3.4 Write predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBZAMNc9KLeu"
   },
   "outputs": [],
   "source": [
    "# eval loop\n",
    "test_preds = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    test_preds.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8FLBTd42IbH"
   },
   "outputs": [],
   "source": [
    "test_preds_flat = [int(item) for items in test_preds for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ID5ctA862Kvk"
   },
   "outputs": [],
   "source": [
    "test_preds_text = [le.inverse_transform([pred])[0] for pred in test_preds_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pEJuNlGz2Mik"
   },
   "outputs": [],
   "source": [
    "test_preds_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gic9YBjm2O2t"
   },
   "outputs": [],
   "source": [
    "f_val = \"\"  # add where to store predictions in csv-format\n",
    "df_test[\"target\"] = test_preds_text\n",
    "df_test[[\"data_index\", \"target\"]].to_csv(f_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1kPBzF6fN0G"
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
